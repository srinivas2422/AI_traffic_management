{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7700f53",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at '<a href=\"#papermill-error-cell\">In [2]</a>'.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd29562-9fb9-40b9-9eae-e9f1fe36e0fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T06:58:21.794872Z",
     "iopub.status.busy": "2024-12-09T06:58:21.793852Z",
     "iopub.status.idle": "2024-12-09T06:58:21.800634Z",
     "shell.execute_reply": "2024-12-09T06:58:21.800634Z"
    },
    "papermill": {
     "duration": 0.014793,
     "end_time": "2024-12-09T06:58:21.802723",
     "exception": false,
     "start_time": "2024-12-09T06:58:21.787930",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the absolute path of the src folder to sys.path\n",
    "sys.path.append(os.path.abspath('../ML/src'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92339ca",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span id=\"papermill-error-cell\" style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">Execution using papermill encountered an exception here and stopped:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "492bacd2-ce8c-4f25-84d6-11743849dce7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T06:58:21.807643Z",
     "iopub.status.busy": "2024-12-09T06:58:21.806648Z",
     "iopub.status.idle": "2024-12-09T06:58:31.575169Z",
     "shell.execute_reply": "2024-12-09T06:58:31.574161Z"
    },
    "papermill": {
     "duration": 9.771413,
     "end_time": "2024-12-09T06:58:31.576168",
     "exception": true,
     "start_time": "2024-12-09T06:58:21.804755",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'data_processing'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m YOLO\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deque\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdata_processing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m extract_frames\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvehicle_detection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m detect_vehicles\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Initialize variables for vehicle tracking\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'data_processing'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import csv\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from collections import deque\n",
    "from data_processing import extract_frames\n",
    "from vehicle_detection import detect_vehicles\n",
    "\n",
    "# Initialize variables for vehicle tracking\n",
    "vehicle_positions = {}  # Dictionary to track vehicle positions across frames\n",
    "vehicle_speeds = deque(maxlen=10)  # Store the speed of tracked vehicles\n",
    "frame_rate = 2  # Assuming 2 frames per second for speed calculation\n",
    "previous_vehicles = []  # Placeholder for previous vehicle positions\n",
    "previous_frame = None  # Placeholder for previous frame\n",
    "\n",
    "def calculate_average_speed(frame_path, previous_vehicles, previous_frame):\n",
    "    \"\"\"Estimate the average speed of vehicles in the frame using vehicle tracking.\"\"\"\n",
    "    current_vehicle_count, current_boxes = detect_vehicles(frame_path)\n",
    "\n",
    "    total_speed = 0\n",
    "    speed_count = 0\n",
    "\n",
    "    if previous_frame is not None and len(previous_vehicles) > 0:\n",
    "        for i, box in enumerate(current_boxes):\n",
    "            # Extract bounding box coordinates and convert them to float\n",
    "            x1, y1, x2, y2 = box.xywh[0].tolist()  # Convert Tensor to list and unpack\n",
    "            current_position = (x1 + x2) / 2  # Take the middle point of the bounding box\n",
    "\n",
    "            if i < len(previous_vehicles):\n",
    "                previous_position = previous_vehicles[i]\n",
    "                speed = abs(current_position - previous_position) * frame_rate  # Speed = distance/time\n",
    "                total_speed += speed\n",
    "                speed_count += 1\n",
    "\n",
    "        if speed_count > 0:\n",
    "            return round(total_speed / speed_count, 2)\n",
    "    return 0\n",
    "\n",
    "def calculate_density(frame_path,vehicle_count):\n",
    "    \"\"\"Calculate traffic density in the frame.\"\"\"\n",
    "    img = cv2.imread(frame_path)\n",
    "    height, width, _ = img.shape\n",
    "    total_area = height * width\n",
    "\n",
    "    if total_area > 0:\n",
    "        density = vehicle_count / (total_area / 100000)  # Normalize to vehicles per 100,000 pixels\n",
    "        return round(density, 6)\n",
    "    return 0\n",
    "\n",
    "def calculate_queue_length(frame_path):\n",
    "    \"\"\"Estimate the queue length of stationary vehicles in the frame.\"\"\"\n",
    "    _, current_boxes = detect_vehicles(frame_path)\n",
    "\n",
    "    vehicle_positions_in_line = []\n",
    "\n",
    "    for box in current_boxes:\n",
    "        # Extract bounding box coordinates and convert to float\n",
    "        x1, _, x2, _ = box.xywh[0].tolist()  # Use .tolist() to convert Tensor to a list of values\n",
    "        vehicle_positions_in_line.append((x1 + x2) / 2)  # Take the midpoint of the vehicle\n",
    "\n",
    "    vehicle_positions_in_line.sort()\n",
    "\n",
    "    if len(vehicle_positions_in_line) > 1:\n",
    "        queue_length = (vehicle_positions_in_line[-1] - vehicle_positions_in_line[0]) * 0.02  # Scaling factor\n",
    "    else:\n",
    "        queue_length = 0\n",
    "\n",
    "    return round(queue_length, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807cc204-7498-4447-809d-bafeda48dd15",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import csv\n",
    "from ultralytics import YOLO\n",
    "from collections import deque\n",
    "from data_processing import extract_frames\n",
    "from vehicle_detection import detect_vehicles\n",
    "from emergency_detection import detect_emergency_vehicles \n",
    "\n",
    "def process_video(video_path, output_frames_folder, output_metrics_folder, model_path=\"../ML/models/yolo11n.pt\", frame_rate=1):\n",
    "    \"\"\"\n",
    "    Process a video to extract frames, calculate metrics (including emergency vehicles), and save results to CSV.\n",
    "    \"\"\"\n",
    "    video_name = os.path.basename(video_path).split('.')[0]\n",
    "    video_frames_folder = os.path.join(output_frames_folder, video_name)\n",
    "    video_metrics_folder = os.path.join(output_metrics_folder, video_name)\n",
    "\n",
    "    # Create necessary folders if not already present\n",
    "    os.makedirs(video_frames_folder, exist_ok=True)\n",
    "    os.makedirs(video_metrics_folder, exist_ok=True)\n",
    "    \n",
    "    # Step 1: Extract frames from the video\n",
    "    extract_frames(video_path, video_frames_folder, frame_rate)\n",
    "\n",
    "    # Step 2: Calculate metrics for each frame and save to CSV\n",
    "    metrics = []\n",
    "    previous_vehicles = []\n",
    "    previous_frame = None\n",
    "\n",
    "    for frame_file in sorted(os.listdir(video_frames_folder)):  # Ensure frame order\n",
    "        frame_path = os.path.join(video_frames_folder, frame_file)\n",
    "\n",
    "        # Calculate metrics\n",
    "        vehicle_count, current_boxes = detect_vehicles(frame_path, model_path)\n",
    "        avg_speed = calculate_average_speed(frame_path, previous_vehicles, previous_frame)\n",
    "        queue_length = calculate_queue_length(frame_path)\n",
    "        density = calculate_density(frame_path,vehicle_count)\n",
    "        print(\"emer\")\n",
    "        emergency = detect_emergency_vehicles(frame_path)\n",
    "\n",
    "        # Append all metrics\n",
    "        metrics.append({\n",
    "            \"Frame\": frame_file,\n",
    "            \"Number_of_Vehicles\": vehicle_count,\n",
    "            \"Average_Speed_km/h\": avg_speed,\n",
    "            \"Traffic_Density\": density,\n",
    "            \"Queue_Length_meters\": queue_length,\n",
    "            \"Emergency_Vehicles\": emergency\n",
    "        })\n",
    "\n",
    "        # Update previous vehicles and previous frame for the next iteration\n",
    "        previous_vehicles = [(box.xywh[0][0].item() + box.xywh[0][2].item()) / 2 for box in current_boxes]  # Convert tensor to float\n",
    "        previous_frame = cv2.imread(frame_path)  # Store the current frame as the previous frame\n",
    "\n",
    "    # Step 3: Save metrics to CSV\n",
    "    metrics_file_path = os.path.join(video_metrics_folder, f\"{video_name}_metrics.csv\")\n",
    "    with open(metrics_file_path, mode='w', newline='') as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=[\"Frame\", \"Number_of_Vehicles\", \"Average_Speed_km/h\", \"Traffic_Density\", \"Queue_Length_meters\", \"Emergency_Vehicles\"])\n",
    "        writer.writeheader()\n",
    "        writer.writerows(metrics)\n",
    "    \n",
    "    print(f\"Metrics for {video_name} saved to {metrics_file_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60410e2d-60a4-4315-ba6c-b47974af9cec",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "video_paths = [\n",
    "    \"../ML/data/videos/video1.mp4\", \n",
    "    \"../ML/data/videos/video2.mp4\", \n",
    "    \"../ML/data/videos/video3.mp4\", \n",
    "    \"../ML//videos/video4.mp4\"\n",
    "]\n",
    "\n",
    "output_frames_folder = \"../ML/outputs/frames/\"\n",
    "output_metrics_folder = \"../ML/outputs/metrics/\"\n",
    "\n",
    "for video_path in video_paths:\n",
    "    process_video(video_path, output_frames_folder, output_metrics_folder, frame_rate=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330f30fc-3cb1-4dc0-a2d5-b4c7cd88f255",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 13.823473,
   "end_time": "2024-12-09T06:58:32.462997",
   "environment_variables": {},
   "exception": true,
   "input_path": "C:\\Users\\asr12\\OneDrive\\Desktop\\AI_traffic_management\\ML\\notebooks\\data_preprocessing.ipynb",
   "output_path": "C:\\Users\\asr12\\OneDrive\\Desktop\\AI_traffic_management\\ML\\notebooks\\data_preprocessing.ipynb",
   "parameters": {},
   "start_time": "2024-12-09T06:58:18.639524",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
